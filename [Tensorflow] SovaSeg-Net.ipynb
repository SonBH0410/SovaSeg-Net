{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIGvP10nEdOr"
      },
      "source": [
        "# **# Import packets and libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alP6_bG7GEG-"
      },
      "outputs": [],
      "source": [
        "# Import packets and libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Activation, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Input, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import MobileNetV2,ResNet50\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okfBJTMDEnO1"
      },
      "source": [
        "# **# Import datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qt8Dm-qE0a5"
      },
      "source": [
        "# **# Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4doVkssGIMJ"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS4KfnXIGKpP"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 256 \n",
        "EPOCHS = 30       \n",
        "BATCH = 8         \n",
        "LR = 1e-4         \n",
        "\n",
        "PATH = \"Dataset_Path\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlQs1vsVwzud"
      },
      "outputs": [],
      "source": [
        "images_arr = []\n",
        "annotations_arr = []\n",
        "for i in range(0,1469) :\n",
        "    path = \"Path to folder contain dataset\"\n",
        "    x = path + \"/images/\" + str(i+1) + \".JPG\"\n",
        "    y = path + \"/annotations/\" + str(i+1) + \".PNG\"\n",
        "    images_arr.append(x)\n",
        "    annotations_arr.append(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8jg82ITi8I-"
      },
      "source": [
        "# **# Import function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcB8uM6cGND1"
      },
      "outputs": [],
      "source": [
        "def load_data(path, split=0.1):\n",
        "\n",
        "    images = sorted(images_arr)\n",
        "    masks = sorted(annotations_arr)\n",
        "\n",
        "    total_size = len(images)                # 1469 total images\n",
        "    valid_size = int(split * total_size)    # 146 images for validation\n",
        "    test_size = int(split * total_size)     # 146 images for test / 1177 images for training\n",
        "\n",
        "    train_x, valid_x = train_test_split(images, test_size=valid_size, random_state=42) \n",
        "    train_y, valid_y = train_test_split(masks, test_size=valid_size, random_state=42)  \n",
        "\n",
        "    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)  \n",
        "    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)  t\n",
        "\n",
        "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpMjGJ_zGPgA"
      },
      "outputs": [],
      "source": [
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    x = x/255.0\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = cv2.resize(x, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    x = x/255.0\n",
        "    (thresh, x) = cv2.threshold(x, 0, 1, cv2.THRESH_BINARY)\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
        "    x.set_shape([IMAGE_SIZE, IMAGE_SIZE, 3]) \n",
        "    y.set_shape([IMAGE_SIZE, IMAGE_SIZE, 1]) \n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(x, y, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(tf_parse) # Tiền xử lý map & batch\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.repeat()\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCq-CCyv_HCZ",
        "outputId": "3d336ded-af89-471b-f9e2-f35352e02056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data:  1177\n",
            "Validation data:  146\n",
            "Testing data:  146\n"
          ]
        }
      ],
      "source": [
        "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(PATH)\n",
        "\n",
        "print(\"Training data: \", len(train_y))\n",
        "print(\"Validation data: \", len(valid_x))\n",
        "print(\"Testing data: \", len(test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikVcf6FFKfV4"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf_dataset(train_x, train_y, batch=BATCH)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch=BATCH)\n",
        "test_dataset = tf_dataset(test_x, test_y, batch=BATCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO0axEBqK_bD"
      },
      "source": [
        "# **# Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2WVfwGQpzpz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Concatenate, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoC1AnX6OFp2"
      },
      "outputs": [],
      "source": [
        "def conv_block(x, num_filters):\n",
        "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = L.BatchNormalization()(x)\n",
        "    x = L.Activation(\"relu\")(x)\n",
        "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = L.BatchNormalization()(x)\n",
        "    x = L.Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def encoder_block(x, num_filters):\n",
        "    x = conv_block(x, num_filters)\n",
        "    p = L.MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def attention_gate(g, s, num_filters):\n",
        "    Wg = L.Conv2D(num_filters, 1, padding=\"same\")(g)\n",
        "    Wg = L.BatchNormalization()(Wg)\n",
        "\n",
        "    Ws = L.Conv2D(num_filters, 1, padding=\"same\")(s)\n",
        "    Ws = L.BatchNormalization()(Ws)\n",
        "\n",
        "    out = L.Activation(\"relu\")(Wg + Ws)\n",
        "    out = L.Conv2D(num_filters, 1, padding=\"same\")(out)\n",
        "    out = L.Activation(\"sigmoid\")(out)\n",
        "    return out * s\n",
        "\n",
        "def decoder_block(x, s, num_filters):\n",
        "    x = L.UpSampling2D(interpolation=\"bilinear\")(x)\n",
        "    s = attention_gate(x, s, num_filters)\n",
        "    x = L.Concatenate()([x, s])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def SPPF_module(x, k = 5):\n",
        "    B, H, W, C = x.shape # Batch - Height - Width - Channel\n",
        "\n",
        "    cv1 = Conv2D(C//2, (1,1), strides=(1,1), padding = 'valid')(x)\n",
        "    cv1 = BatchNormalization()(cv1) \n",
        "    cv1 = tf.nn.silu(cv1) \n",
        "    mp1 = MaxPooling2D(pool_size = (k, k), strides = (1, 1), padding = 'same')(cv1) \n",
        "    mp2 = MaxPooling2D(pool_size = (k, k), strides = (1, 1), padding = 'same')(mp1)\n",
        "    mp3 = MaxPooling2D(pool_size = (k, k), strides = (1, 1), padding = 'same')(mp2)\n",
        "\n",
        "    out = Concatenate(axis=-1)([cv1, mp1, mp2, mp3])\n",
        "    out = Conv2D(C, (1,1), strides=(1,1), padding = 'valid')(out)\n",
        "    out = BatchNormalization()(out)\n",
        "    out = tf.nn.silu(out)\n",
        "    return out\n",
        "\n",
        "def build_vgg16_attention_unet(input_shape):\n",
        "    \"\"\" Input \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\" Pre-trained VGG19 Model \"\"\"\n",
        "    vgg16 = VGG16(include_top = False, weights = \"imagenet\", input_tensor = inputs)\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    s1 = vgg16.get_layer(\"block1_conv2\").output;\n",
        "    s2 = vgg16.get_layer(\"block2_conv2\").output;\n",
        "    s3 = vgg16.get_layer(\"block3_conv3\").output;\n",
        "    s4 = vgg16.get_layer(\"block4_conv3\").output;\n",
        "    b1 = vgg16.get_layer(\"block5_conv3\").output;\n",
        "    b2 = SPPF_module(b1, k = 5);\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    # b1 = vgg19.get_layer(\"block5_conv4\").output\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = decoder_block(b2, s4, 512);\n",
        "    d2 = decoder_block(d1, s3, 256);\n",
        "    d3 = decoder_block(d2, s2, 128);\n",
        "    d4 = decoder_block(d3, s1, 64) ;\n",
        "\n",
        "    \"\"\" Output \"\"\"\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4);\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBpxQng-_jUO"
      },
      "outputs": [],
      "source": [
        "input = (256, 256, 3)\n",
        "model = build_vgg16_attention_unet(input) # OUTPUT (256, 256, 1)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbvGNqwPMEB9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.losses import binary_crossentropy, BinaryCrossentropy\n",
        "\n",
        "beta = 0.25\n",
        "alpha = 0.25\n",
        "gamma = 2\n",
        "epsilon = 1e-5\n",
        "smooth = 1e-15\n",
        "\n",
        "def dice_coef( y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + K.epsilon()) / (\n",
        "            K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
        "\n",
        "def sensitivity(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "def specificity( y_true, y_pred):\n",
        "    true_negatives = K.sum(\n",
        "        K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())\n",
        "\n",
        "def convert_to_logits(y_pred):\n",
        "    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(),\n",
        "                              1 - tf.keras.backend.epsilon())\n",
        "    return tf.math.log(y_pred / (1 - y_pred))\n",
        "\n",
        "def weighted_cross_entropyloss(y_true, y_pred):\n",
        "    y_pred = convert_to_logits(y_pred)\n",
        "    pos_weight = beta / (1 - beta)\n",
        "    loss = tf.nn.weighted_cross_entropy_with_logits(logits=y_pred,\n",
        "                                                    labels=y_true,\n",
        "                                                    pos_weight=pos_weight)\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "def generalized_dice_coefficient( y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (\n",
        "            K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss( y_true, y_pred):\n",
        "    loss = 1 - generalized_dice_coefficient(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def confusion( y_true, y_pred):\n",
        "    y_pred_pos = K.clip(y_pred, 0, 1)\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "    y_pos = K.clip(y_true, 0, 1)\n",
        "    y_neg = 1 - y_pos\n",
        "    tp = K.sum(y_pos * y_pred_pos)\n",
        "    fp = K.sum(y_neg * y_pred_pos)\n",
        "    fn = K.sum(y_pos * y_pred_neg)\n",
        "    prec = (tp + smooth) / (tp + fp + smooth)\n",
        "    recall = (tp + smooth) / (tp + fn + smooth)\n",
        "    return prec, recall\n",
        "\n",
        "def true_positive(y_true, y_pred):\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    tp = (K.sum(y_pos * y_pred_pos) + smooth) / (K.sum(y_pos) + smooth)\n",
        "    return tp\n",
        "\n",
        "def true_negative( y_true, y_pred):\n",
        "    smooth = 1\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    y_neg = 1 - y_pos\n",
        "    tn = (K.sum(y_neg * y_pred_neg) + smooth) / (K.sum(y_neg) + smooth)\n",
        "    return tn\n",
        "\n",
        "def jacard_similarity( y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union = K.sum((y_true_f + y_pred_f) - (y_true_f * y_pred_f))\n",
        "    return intersection / union\n",
        "\n",
        "def jacard_loss(y_true, y_pred):\n",
        "    return 1 - jacard_similarity(y_true, y_pred)\n",
        "\n",
        "def ssim_loss(y_true, y_pred):\n",
        "    return 1 - tf.image.ssim(y_true, y_pred, max_val=1)\n",
        "\n",
        "def binary_dice(y_true, y_pred):\n",
        "    return 0.5 *binary_crossentropy(y_true, y_pred) + dice_loss( y_true, y_pred)\n",
        "\n",
        "def FocalLoss(y_true, y_pred):\n",
        "    alpha = 0.26\n",
        "    gamma = 2.3\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "\n",
        "    inputs = K.flatten(y_pred)\n",
        "    targets = K.flatten(y_true)\n",
        "\n",
        "    BCE = K.binary_crossentropy(targets, inputs)\n",
        "    BCE_EXP = K.exp(-BCE)\n",
        "    focal_loss = K.mean(alpha * K.pow((1-BCE_EXP), gamma) * BCE)\n",
        "\n",
        "    return focal_loss\n",
        "def joint_loss1(y_true, y_pred):\n",
        "    focal_loss1 = FocalLoss(y_true, y_pred)\n",
        "    ms_ssim_loss1 = ssim_loss(y_true, y_pred)\n",
        "    jacard_loss1 = jacard_loss(y_true, y_pred)\n",
        "    loss =  (focal_loss1 + ms_ssim_loss1 + jacard_loss1)/3\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghiVkvin3HVz"
      },
      "source": [
        "# **# Compile Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyCLwo7IMMlt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_path = \"Save-epoch-path.{epoch:02d}.h5\"\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=False,\n",
        "    save_weights_only=True,\n",
        "    mode='auto',\n",
        "    save_freq='epoch'\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=False),\n",
        "    checkpoint_callback\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtS4rqmdMFOu",
        "outputId": "e7010b6b-aebf-4e0b-8478-d8c322067981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "148\n",
            "19\n"
          ]
        }
      ],
      "source": [
        "train_steps = len(train_x) // BATCH\n",
        "valid_steps = len(valid_x) // BATCH\n",
        "\n",
        "if len(train_x) % BATCH != 0:\n",
        "    train_steps += 1\n",
        "if len(valid_x) % BATCH != 0:\n",
        "    valid_steps += 1\n",
        "\n",
        "print(train_steps)\n",
        "print(valid_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmRzz3bVMmI1"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Nadam(LR)\n",
        "metrics = [dice_coef, jacard_similarity, tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
        "\n",
        "model.compile(loss=joint_loss1, optimizer=opt, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Nadam(LR)\n",
        "metrics = [dice_coef, jacard_similarity, tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
        "\n",
        "model.compile(loss=joint_loss1, optimizer=opt, metrics=metrics)\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=valid_dataset,\n",
        "    epochs=30,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_steps=valid_steps,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4ARKqVjkwa4"
      },
      "outputs": [],
      "source": [
        "model_path = 'Best-weight'\n",
        "model.load_weights(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSwiD3TLNLe5"
      },
      "outputs": [],
      "source": [
        "test_dataset = tf_dataset(test_x, test_y, batch=BATCH)\n",
        "\n",
        "test_steps = (len(test_x)//BATCH)\n",
        "if len(test_x) % BATCH != 0:\n",
        "    test_steps += 1\n",
        "model.evaluate(test_dataset, steps=test_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXInvTL8vbMw"
      },
      "outputs": [],
      "source": [
        "img_path = cv2.imread('ultrasound-image-path')\n",
        "img_pred = model.predict(np.expand_dims(img_path, axis = 0))[0] >0.5"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
